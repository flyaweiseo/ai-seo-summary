import streamlit as st
import openai
import trafilatura
from newspaper import Article

# é é¢è¨­å®š
st.set_page_config(page_title="AI SEO é¡§å•æ‘˜è¦å·¥å…·", page_icon="ğŸ“Œ")
openai.api_key = st.secrets["OPENAI_API_KEY"]

# âœ… æ­£ç¢ºç‰ˆæœ¬ fetch_articleï¼ˆè™•ç† trafilatura å›å‚³ strã€ä¸ä½¿ç”¨ .get()ï¼‰
def fetch_article(url):
    downloaded = trafilatura.fetch_url(url)
    if downloaded:
        text = trafilatura.extract(downloaded)
        if text:
            metadata = trafilatura.metadata.extract_metadata(downloaded)
            title = metadata.title if metadata and metadata.title else "ç„¡æ¨™é¡Œæ–‡ç« ï¼ˆtrafilaturaï¼‰"
            return {
                "content": text,
                "title": title
            }

    # â• å‚™æ´æ–¹æ¡ˆï¼šnewspaper3k
    try:
        article = Article(url)
        article.download()
        article.parse()
        if article.text:
            return {
                "content": article.text,
                "title": article.title or "ç„¡æ¨™é¡Œæ–‡ç« ï¼ˆnewspaperï¼‰"
            }
    except:
        return None

    return None

# âœ… GPT ç¹é«”ä¸­æ–‡æ‘˜è¦é‚è¼¯
def summarize_article(content, title="ï¼ˆç„¡æ¨™é¡Œï¼‰"):
    prompt = f"""
ä½ æ˜¯ä¸€ä½æœ‰15å¹´ç¶“é©—çš„è³‡æ·±SEOé¡§å•ï¼Œæ“…é•·å¿«é€Ÿç†è§£ä¸­è‹±æ–‡å…§å®¹ã€çµ±æ•´è³‡è¨Šä¸¦æç…‰é‡é»ã€‚

è«‹å°‡ä¸‹æ–¹å…§å®¹ä¸è«–æ˜¯ä¸­æ–‡æˆ–è‹±æ–‡ï¼Œçš†ä»¥ã€Œç¹é«”ä¸­æ–‡ã€è¼¸å‡ºæ¢åˆ—æ‘˜è¦èˆ‡çµèªç¸½çµã€‚

ã€è¼¸å‡ºæ ¼å¼ã€‘
- è«‹æ–¼é–‹é ­åŠ ä¸Šæ–‡ç« æ¨™é¡Œï¼Œæ ¼å¼ç‚ºï¼š# æ–‡ç« æ¨™é¡Œï¼š{title}
1. æ¢åˆ—å¼æ‘˜è¦ï¼šè«‹ä¾ç…§å…§å®¹é‚è¼¯ï¼ŒåŠ å…¥é‡é»æ®µè½æ¨™é¡Œï¼ˆä½¿ç”¨ H2 æˆ– H3 æ¨™è¨˜ï¼‰ï¼Œæ¯å€‹æ®µè½ä¸‹ç”¨æ¢åˆ—å¼å¯«å‡ºé‡é»ï¼ˆä½¿ç”¨ - é–‹é ­ï¼‰ï¼Œè³‡è¨Šåˆ†å±¤æ¸…æ¥šã€ä¹¾æ·¨æœ‰æ¢ç†ã€‚
2. çµèªç¸½çµï¼šè«‹ä»¥ä¸è¶…é 500 å­—çš„æ–¹å¼ï¼Œä»¥ç¹é«”ä¸­æ–‡å¯«å‡ºé€™ç¯‡æ–‡ç« çš„ç²¾éš¨ï¼Œè®“æœªé–±è®€åŸæ–‡è€…ä¹Ÿèƒ½å¿«é€ŸæŒæ¡é‡é»ã€‚

ã€æ–‡ç« å…§å®¹ã€‘ï¼š
{content}
"""
    client = openai.OpenAI(api_key=openai.api_key)
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4,
        max_tokens=2000
    )
    return response.choices[0].message.content.strip()

# âœ… Streamlit ä¸»ä»‹é¢
st.title("ğŸ” AI SEO é¡§å•ï¼šç¶²é æˆ–è²¼æ–‡æ‘˜è¦å·¥å…·ï¼ˆä¸­è‹±æ–‡è¼¸å…¥ï¼Œç¹ä¸­è¼¸å‡ºï¼‰")

tab1, tab2 = st.tabs(["ğŸŒ è²¼ç¶²å€åˆ†æ", "âœï¸ è²¼ä¸ŠåŸæ–‡"])

# ğŸ‘‰ Tab 1ï¼šç¶²å€æ“·å–åˆ†æ
with tab1:
    url = st.text_input("è«‹è¼¸å…¥ç¶²é é€£çµï¼š")
    if url:
        with st.spinner("æ“·å–èˆ‡åˆ†æä¸­..."):
            data = fetch_article(url)
            if data and "content" in data and data["content"]:
                content = data["content"]
                title = data["title"]
                summary = summarize_article(content, title)

                st.subheader("ğŸ“Œ æ¢åˆ—å¼æ‘˜è¦ + ç²¾è¯ç¸½çµ")
                st.markdown(summary)

                with st.expander("ğŸ“„ åŸå§‹æ–‡ç« å…§å®¹"):
                    st.markdown(f"**åŸå§‹æ–‡ç« æ¨™é¡Œï¼š** {title}")
                    st.write(content)
            else:
                st.warning("âš ï¸ æ“·å–å¤±æ•—ï¼Œå¯èƒ½è©²ç¶²ç«™ä½¿ç”¨é˜²çˆ¬èŸ²ï¼Œè«‹æ”¹ç”¨ä¸‹æ–¹ã€âœï¸ è²¼ä¸ŠåŸæ–‡ã€‘åˆ†æ")

# ğŸ‘‰ Tab 2ï¼šæ‰‹å‹•è²¼æ–‡åˆ†æ
with tab2:
    title_input = st.text_input("æ–‡ç« æ¨™é¡Œï¼ˆå¯ç©ºç™½ï¼‰")
    content_input = st.text_area("è«‹è²¼ä¸Šä½ è¦åˆ†æçš„æ–‡ç« å…§å®¹ï¼š", height=300)
    if st.button("ç”Ÿæˆæ‘˜è¦", key="manual"):
        if content_input.strip():
            summary = summarize_article(content_input, title_input or "æ‰‹å‹•è¼¸å…¥æ–‡ç« ")
            st.subheader("ğŸ“Œ æ¢åˆ—å¼æ‘˜è¦ + ç²¾è¯ç¸½çµ")
            st.markdown(summary)
        else:
            st.error("âŒ å…§å®¹ä¸èƒ½ç‚ºç©º")
